---
title: 20250619
date: 2025-09-17 21:18:03
tags:
---

Abstract: 读了些论文，做了些复现，帮jungle做了个验证

1. Don’t Overthink It: A Survey of Efficient R1-style Large Reasoning Models
这是一篇探讨在acc不降的情况下token length缩短的综述。

2. Chain of Draft: Thinking Faster by Writing Less
此篇被知乎老哥锐评为一句“with 5 words at most.”的prompt水了一篇论文
token length缩短效果不错，与jungle保持一致，但根据我的额外测试，在更加复杂的问题上表现不佳，相比之下jungle的acc好很多
这篇论文很短，用词很简单，以至于我二三十分钟就读完了，打破纪录！

3. Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning
选择较高信息熵的20%的token来训练会让效果更好
mark了，十分有智慧

4. The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning
大幅魔改了文章中EMINF对于信息熵控制的实现代码，实验jungle的猜想，但很可惜这个猜想没打赢。
但学了一种基于修改loss的控制信息熵方法，十分有趣。
这个方法可以更加泛用，mark了。

忘记还干什么了

看起来很空，感觉该更快速更多时间读论文了，我发现跟同学一起一边读一边讨论论文中的细节能让我更快的阅读。

近两个月阅读论文均使用zotero&全英文阅读，很爽，这次12月我必要过六级。